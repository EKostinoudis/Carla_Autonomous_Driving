# model name: CIL_multiview_rllib or CIL_multiview_rllib_stack
model: CIL_multiview_rllib

# use CILv2_vec_env instead of CILv2_env
use_vec_env: false

# file to a checkpoint from which we start the training
checkpoint_file: models/CILv2_multiview/_results/checkpoints/CIL_multiview_actor_critic/CIL_multiview_actor_critic_final.pth

# path the the models config file
path_to_conf: ./models/CILv2_multiview/_results/Ours/Town12346_5/config40.json

# numbe of cpus and gpus passed to ray init
# num_cpus must be at least num_workers + 1 (if null we use this value)
# num_gpus must be bigger than the given gpus
# these values can also be null (None in Python) so the default value will be used
num_cpus: null
num_gpus: null

# for the value function (critic) pretraining
pretrain_value: true # enables pretraining
pretrain_iters: 2

train_iters: 2
num_workers: 2 # number of parallel environments
training_gpus: 1 # number of gpus for the training (updating the weights)
worker_gpus: 0.0 # number of gpus for the sampling (collecting the observations)
checkpoint_freq: 5 # frequency for the checkpoints

# extra parameters for the PPOConfig
extra_params:
  lr: 5.0e-05
  train_batch_size: 4000
  sgd_minibatch_size: 128
  num_sgd_iter: 30

  gamma: 0.99
  clip_param: 0.3

  vf_clip_param: 10.0
  vf_loss_coeff: 1.0

  use_gae: true
  lambda_: 1.0

  use_kl_loss: true
  kl_coeff: 0.2
  kl_target: 0.01

  shuffle_sequences: true
  entropy_coeff: 0.0
  entropy_coeff_schedule: null


  explore: true
  exploration_config:
    type: StochasticSampling
